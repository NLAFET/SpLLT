\documentclass{article}
\pagenumbering{arabic}

\usepackage{url}
\usepackage{color}
\usepackage{verbatim}
\usepackage{tikz}
\usepackage{gnuplot-lua-tikz}

\usepackage{xspace}

%\usepackage[utf8]{inputenc}
%\usepackage{fontspec}
\usepackage{pgfplots}

\usepackage[procnames]{listings}
\lstset{ %
  backgroundcolor=\color{gray98},    % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\tt\small, % \prettysmall      % the size of the fonts that are used for the code
  breakatwhitespace=false,          % sets if automatic breaks should only happen at whitespace
  breaklines=true,                  % sets automatic line breaking
  showlines=true,                  % sets automatic line breaking
  captionpos=b,                     % sets the caption-position to bottom
  commentstyle=\color{gray30},      % comment style
  extendedchars=true,               % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,                     % adds a frame around the code
  keepspaces=true,                  % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{amblu},       % keyword style
  procnamestyle=\color{amred},       % procedures style
  language=[95]fortran,             % the language of the code
  numbers=left,                     % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                    % how far the line-numbers are from the code
  numberstyle=\tiny\color{gray20}, % the style that is used for the line-numbers
  rulecolor=\color{gray20},          % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                 % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,           % underline spaces within strings only
  showtabs=false,                   % show tabs within strings adding particular underscores
  stepnumber=2,                     % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{amblu},       % string literal style
  tabsize=2,                        % sets default tabsize to 2 spaces
  % title=\lstname,                    % show the filename of files included with \lstinputlisting; also try caption instead of title
  procnamekeys={call}
}

\usepackage{color}
\definecolor{gray98}{rgb}{0.98,0.98,0.98}
\definecolor{gray20}{rgb}{0.20,0.20,0.20}
\definecolor{gray25}{rgb}{0.25,0.25,0.25}
\definecolor{gray16}{rgb}{0.161,0.161,0.161}
\definecolor{gray60}{rgb}{0.6,0.6,0.6}
\definecolor{gray30}{rgb}{0.3,0.3,0.3}
\definecolor{bgray}{RGB}{248, 248, 248}
\definecolor{amgreen}{RGB}{77, 175, 74}
% \definecolor{amblu}{RGB}{72, 88, 102}
\definecolor{amblu}{RGB}{55, 126, 184}
\definecolor{amred}{RGB}{228,26,28}
\definecolor{amyellow}{RGB}{237,177,32}
\definecolor{ampurple}{RGB}{126,47,142}
\newcommand{\mye}[1]{\textcolor{amyellow}{#1}\xspace}
\newcommand{\mgr}[1]{\textcolor{amgreen}{#1}\xspace}
\newcommand{\mbl}[1]{\textcolor{amblu}{#1}\xspace}
\newcommand{\mre}[1]{\textcolor{amred}{#1}\xspace}
\newcommand{\mbk}[1]{\textcolor{black}{#1}\xspace}
\newcommand{\mbp}[1]{\textcolor{ampurple}{#1}\xspace}

\input{nlafet_style.sty}

\newcommand{\starpu}{{StarPU}\xspace}
\newcommand{\parsec}{{PaRSEC}\xspace}
\newcommand{\TODO}{\alert{TODO}\xspace}

\bibliographystyle{siam}

%-----------------------------------------------------------------------
%
% include macros
%
\input nlafet_macros.tex
%-----------------------------------------------------------------------



\newcommand{\stfccovertitle}
{Experiments with sparse Cholesky using runtime systems}


\newcommand{\theabstract}{We describe the development of a prototype code for 
the solution of large symmetric positive definite sparse systems that is
efficient on parallel architectures.
}

\textwidth  16.18cm
\textheight 23.4cm
\oddsidemargin -0.2mm
\evensidemargin -0.2mm
\def\baselinestretch{1.1}
\topmargin -8.4mm

\newcommand{\n}[1][1]{\vspace*{#1\baselineskip}\noindent}
\newcommand{\ISD}[1]{\begin{center}\n[.4]\textcolor{red}{ISD\
 \hspace*{0.15em} \fbox{\parbox{.8\textwidth}{#1}}}\n[.4]\end{center}}
\newcommand{\HSD}[1]{\begin{center}\n[.4]\textcolor{green}{FL\
\hspace*{0.15em} \fbox{\parbox{.9\textwidth}{\texttt{#1}}}}\n[.4]\end{center}}
\newcommand{\ASH}[1]{\begin{center}\n[.4]\textcolor{brown}{JH\
\hspace*{0.15em} \fbox{\parbox{.9\textwidth}{\texttt{#1}}}}\n[.4]\end{center}}

\newcommand{\metis}{{\sc Me$\!$T$\!$iS\ }}

\hyphenpenalty=10000
\widowpenalty=10000
\sloppy

\begin{document}


\begin{titlepage}

\vspace*{-0.5cm}

\vspace{1.0 cm}

{\Large \bf
\begin{center}
   \stfccovertitle
\end{center}}

\begin{center}
\mbox{} \\
      Iain Duff\footnotemark[1], 
      Jonathan Hogg\footnotemark[1], and Florent Lopez\footnotemark[1]
     
\mbox{} \\
\end{center}

\vspace{1.0cm}


\noindent
{\large ABSTRACT}

\vspace{0.3cm}
\noindent
\theabstract

\vspace{0.6cm}

\begin{description}
\item [Keywords:] sparse Cholesky, SPD systems, runtime systems, STARPU, PaRSEC
\item [AMS(MOS) subject classifications:]  65F30, 65F50
\end{description}

\vspace{0.1 cm}

\noindent \rule{15cm}{0.001in}
\vspace{0.1 cm}

\begin{description}

\item [$^1$] Scientific Computing Department, STFC Rutherford 
Appleton Laboratory,
Harwell Campus,\\ Oxfordshire, OX11 0QX, UK.
\end{description}
\noindent
Correspondence to: florent.lopez@stfc.ac.uk\\
This work was supported by the FET-HPC H2020 NLAFET grant number xxxx.\\


\vspace{1.1 cm}
\noindent \today

\end{titlepage}

\newpage
\setcounter{page}{1}
\pagenumbering{arabic}

\section{Introduction} \label{sec:introduction}

In this work we investigate the use a runtime system for the
implementation of a sparse Cholesky solver with the aim to efficiently
exploit multicore architectures. Since their introduction multicore
processor have become increasingly popular and can be found nowadays
in the vast majority of high performance computing platforms. Despite
their popularity, exploiting the capabilities of multicore processors
remain a challenge. To cope with these multicore hardware, DAG-based
algorithms have been shown to be extremely efficient in terms of
performance and scalability. They have been widely employed in the
context dense linear algebra such as in the
PLASMA~\cite{a.d.d.h.ea:09}. Because of their deficiencies in this
context they have then been used with sparse algorithm such as the
\texttt{HSL\_MA87} solver which implements a sparse Cholesky
factorization and \texttt{HSL\_MA87} which implements a multifrontal
QR method.

When designing scientific computing libraries for shared-memory
multicore architecture, the classical approach consists in developing
ad-hoc scheduler which rely on the knowledge of the algorithm and
implemented using a low-level multithreading library such as pthread
(POSIX threads) to manage synchronisations and enforce dependencies
between processes. In this work, instead, we use a runtime system as a
software layer between the architecture and the application. In this
approach the application is then implemented using a high-level API
provided by the runtime system the low level details such as data
consistency across the architecture and task scheduling are delegated
to the runtime system. In addition, in this work we use a Sequential
Task Flow (STF) programming model which allows us to simply express
the parallel code from the sequential one.

\section{Sparse Cholesky factorization}\label{sec:chol}
\setcounter{equation}{0}
\setcounter{table}{0}
\setcounter{figure}{0}

\section{Sequential Task Flow parallel programming model}\label{sec:runtime}

In this work we propose to exploit a \textit{Sequential Task Flow
  (STF)} programming model for the implementation of a parallel
task-based Cholesky factorization on top of a runtime system. In this
model the detection of dependencies between task relies on a data
analysis of input and output data in order to guarantee the
\textit{sequential consistency} of operations during a parallel
execution. This analysis is often refer to as a \textit{superscalar}
analysis in reference to the dependency detection between instructions
that are performed in superscalar processors. In this context the
dependency graph is used to allow the parallel execution of
independent instructions which is referred to as instruction-level
parallelism and increases the instruction throughput. The STF model is
the most commonly used paradigm for the parallelization of DAG-based
algorithms that have become more and more popular in the scientific
computing community. For example, several dense linear algebra
software packages such as PLASMA~\cite{a.d.d.h.ea:09} and
FLAME~\cite{i.c.q.q.ea:12} use this paradigm in their
implementations. One reason for such a popularity is that it is
extremely easy to use this model as it the parallel code is very
similar from the sequential one. Essentially, for a given sequential
algorithm, the STF code is implemented by replacing the function calls
(i.e. the execution of tasks in the case of a DAG-based algorithm)
with the asynchronous submission of this task to a runtime system in
charge of the scheduling. Depending of the data access that are
provided, the runtime system automatically detects the dependencies
between the tasks. The sequential consistency is then ensured by the
fact that the order of submission of tasks correspond to the
sequential order.

\begin{figure}[!h]
  \begin{minipage}{0.5\textwidth}
    \centering \lstset{language=C, procnamekeys={}}
    \lstinputlisting{listings/seq-example.c}
    \caption{\label{fig:seq-example}Simple of a sequential code}
    \vspace{0.5cm}
    \centering \lstinputlisting{listings/stf-example.c}
    \caption{\label{fig:stf-example}STF code}
  \end{minipage}
  \hspace{0.5cm}
  \begin{minipage}{0.5\textwidth}
    \centering
    \includegraphics[width=0.7\textwidth]{figures/example_dag}
    \caption{\label{fig:dag-example}DAG corresponding to the
      sequential code presented in Figure~\ref{fig:stf-example}}
  \end{minipage}
  %% \caption{\label{fig:seq-example} Simple example of a sequential code
  %%   on the left with the corresponding DAG represented on the right.}
\end{figure}

As an example, we consider the sequential code in
Figure~\ref{fig:seq-example} for which the corresponding DAG is
represented in Figure~\ref{fig:dag-example}. Based on a STF model, the
parallel version of this code is illustrated in
Figure~\ref{fig:stf-example}. In the sequential code, the two
functions \textit{f} and \textit{g} manipulate arrays \textit{x} and
\textit{y}. The STF code is obtain by submitting the tasks that
consists of a kernels funtion (\textit{f} or \textit{g} in this
example) together with a data which is associated with a data access
which can possibly be \textit{R} when the data is read, \textit{W}
when the data is modified and \textit{RW} when the data is read and
modified.

As we have seen with this simple example is that the STF model is
extremely easy to exploit and this characteristic is certainly one of
the main reason for its extreme popularity in the HPC community. This
model, however, has several drawbacks that may affect the performance
and scalability of parallel codes relying on it. First the task are
issued and submitted to the runtime system sequentially. In the case
where, for a given DAG, the task granularity is small compared to the
time needed for building and submitting a task, the parallel execution
might be constraint by the time spent in the submission loop that is
setting up the DAG. To avoid this issue, it might be interesting to
consider a \textit{recursive} model where tasks might be used to
submit other tasks enabling the distribution of the cost for building
the DAG between the resources instead of doing it in a single
submission loop. This might be implemented for example with
\textit{callback} functions that are executed upon task completion and
can be use for the submission of tasks depending on the task that just
finished its execution. Another issue arising with the STF model comes
from the fact that the whole DAG is unrolled during the parallel
execution and every tasks in the DAG is stored in order to track task
dependencies. In the case where the DAG is extremely large, handling
and storing the DAG might represent an important overhead in terms of
computational cost and memory storage. Regarding this issue, even if
the recursive model allows to mitigate the problem, it my be necessary
to consider a radically different model such a the Parametrized Task
Graph (PTG) model which is introduced in~\cite{c.l:95}. In this model,
task dependencies are explicitly encoded according to the data-flow of
each task and as a results the whole DAG can be expressed in a compact
format. 

%% In the present paper we mainly focus on the 

\section{Runtime systems}\label{sec:runtime}
\setcounter{equation}{0}
\setcounter{table}{0}
\setcounter{figure}{0}

The popularity of task-based algorithms push the OpenMP standard to
introduce the \textit{task} construct in the version 3.0 its API. Then
motivated by the popularity of the STF model, the OpenMP board decided
to include the \textit{depend} construct in the version 4.0 allowing
users to express dependencies between tasks in a way complying with
the STF model. In this work we propose an OpenMP implementation of our
Cholesky solver and show advantages of using this standard in terms of
performance, scalability and productivity. However because many
features are still unavailable in the standard we also developed
another version based on the StarPU runtime system. Both
implementations of our solver rely on a STF model, but the
StarPU-based implementation might benefit from a wider range of
feature available with StarPU. For example, although we focus on
shared-memory architectures in this work, the StarPU version might be
extended into a distributed-memory version whereas OpenMP doesn't
provide any possibility to run on distributed memory architectures.

In order to introduce the features provided by StarPU API and the
features provided by this runtime system, we show in
Figure~\ref{fig:stf-starpu-example} an example of a StarPU-based
implementation for the simple example presented in
Figure~\ref{fig:seq-example}. The task submission is done through the
\texttt{starpu\_task\_insert} function that tasks in input a
\textit{codelet} and a set of \textit{handles}. A codelet correspond
to the description of a task and include a list of computational
resources where the task can be executed as well as the corresponding
computational kernels. In our example the codelet \texttt{g\_cl}
describe a task that can be executed on a CPU and a CUDA device
(\texttt{STARPU\_CPU | STARPU\_CUDA}) respectively with the kernels
\texttt{g\_cpu\_func} and \texttt{g\_cuda\_func}. The data handles
represents a piece of data that is accessed in the task and can be
read (\texttt{STARPU\_R}), written (\texttt{STARPU\_W}) or read and
written (\texttt{STARPU\_RW}). In order to be accessed, a data handle
must be \textit{registered} to the runtime system by providing
information such as a pointer on the data, its size and type. These
information allows StarPU to automatically perform the data transfer
between the memory nodes during the execution. For example, when a
data needs to be accessed on a GPU device, the runtime system
automatically transfer it to the device memory node. As a results
StarPU is capable of ensuring the data consistency multiple
nodes. When all the tasks have been submitted to the runtime system,
we wait for their completion by calling the routine
\texttt{starpu\_task\_wait\_for\_all}.

\begin{figure}[!h]
  \lstset{language=C, procnamekeys={},escapechar=>}
  \centering \lstinputlisting{listings/stf-starpu-example.c}
  \caption{\label{fig:stf-starpu-example}Simple example of a parallel version
    of the sequential code in Figure~\ref{fig:seq-example} using a STF
    model with \starpu.}
\end{figure}

\section{Parallelisation of a task-based Cholesky factorization using a STF programming model}
\label{sec:experiments}



\begin{figure}[!h]
  \centering \lstinputlisting{listings/spllt_facto_stf.f90}
\caption{\label{fig:activation-pseudocode-1d}Pseudo-code for the
  sparse Cholesky factorization using a STF model.}
\end{figure}

\section{Experimental results}\label{sec:experiments}

\begin{table}[htbp]
    \begin{center}
      \input{data/table_cmp_facto.tex}
    \end{center}
    \caption{Factorization times (second) obtained with MA87 and SpLLT
      (i.e. MA87\_starpu). The factorizations were run with the block
      sizes \texttt{nb=(256, 384, 512, 768, 1024)} on 28 cores and
      \texttt{nemin=32}. The lowest factorization times are
      represented in bold.}
\end{table}

\section{Concluding remarks}\label{sec:conclusions}
This report has described in detail the development of a new

 
\section*{Code Availability}
A development version of the Cholesky factorization software used in this 
paper may be checked out of
our source code repository using the following command:

\begin{verbatim}
   svn co -r612 http://ccpforge.cse.rl.ac.uk/svn/spral/branches/xxxxxxx
\end{verbatim}

This code has not yet been optimised and so is not yet
part of the HSL or SPRAL libraries that are we develop
and maintain at the Rutherford Appleton Laboratory (see
\url{http://www.hsl.rl.ac.uk/} and \url{http://www.numerical.rl.ac.uk/spral/}).

\clearpage
\bibliography{flipflapflopBib}

\appendix

\section{Test problems}\label{appendix}
\setcounter{equation}{0}
\setcounter{table}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\renewcommand{\thetable}{A.\arabic{table}}


In Table~\ref{Tbl:Problems} we list  our test problems along with 
their characteristics. The problems are from the 
University of Florida Sparse Matrix Collection  and are chosen 
to represent a wide range of sparsity structures.

\end{document}
